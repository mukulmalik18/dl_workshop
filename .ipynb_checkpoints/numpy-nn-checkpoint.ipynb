{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are keeping 20% of data samples as test set\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, target, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 120, 30)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(test_X), len(train_y), len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idim = train_X[0].shape[0] # size of input layer - \"4\"\n",
    "hdim = 100 # size of hidden layers(100 nodes)\n",
    "odim = len(np.unique(train_y)) # size of output layer - \"3\"\n",
    "\n",
    "alpha = 0.001 # Learning rate\n",
    "reg_lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = {'W1': None, 'b1': None, 'W2': None, 'b2': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prop(model, x):\n",
    "    \n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    \n",
    "    z1 = x.dot(W1) + b1\n",
    "    a1 = np.tanh(z1)\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    exp_scores = np.exp(z2)\n",
    "    probs = exp_scores/np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(model, x):\n",
    "    \n",
    "    probs = forward_prop(model, x)\n",
    "    \n",
    "    targets = -np.log(probs[range(len(train_X)), train_y])\n",
    "    loss = np.sum(targets)\n",
    "    \n",
    "    loss += reg_lambda/2 * (np.sum(np.square(model['W1'])) + np.sum(np.square(model['W2'])))\n",
    "    return 1./len(train_X) * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    probs = forward_prop(model, x)\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "def get_accuracy(model, x, y):    \n",
    "    predictions = predict(model, x)\n",
    "    accuracy = np.sum(y == predictions)/len(x)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainer(hdim, epochs):\n",
    "    \n",
    "    W1 = np.random.rand(idim, hdim)/np.sqrt(idim)\n",
    "    b1 = np.zeros((1, hdim))\n",
    "    W2 = np.random.randn(hdim, odim)/np.sqrt(hdim)\n",
    "    b2 = np.zeros((1, odim))\n",
    "    \n",
    "    model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    \n",
    "    # For whole batch\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        z1 = train_X.dot(W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "        z2 = a1.dot(W2) + b2\n",
    "        exp_scores = np.exp(z2)\n",
    "        probs = exp_scores/np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        \n",
    "        # Backpropagation\n",
    "        delta3 = probs\n",
    "        delta3[range(len(train_X)), train_y] -= 1\n",
    "        dW2 = (a1.T).dot(delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "        dW1 = np.dot(train_X.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "        \n",
    "        # Add regularization terms\n",
    "        dW2 += reg_lambda * W2\n",
    "        dW1 += reg_lambda * W1\n",
    "        \n",
    "        # Gradient descent\n",
    "        W1 += -alpha * dW1\n",
    "        b1 += -alpha * db1\n",
    "        W2 += -alpha * dW2\n",
    "        b2 += -alpha * db2\n",
    "        \n",
    "        model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        print(\"Loss after iteration %d: %f\"%(epoch, get_loss(model, train_X)))\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Accuracy after iteration %d: %f\"%(epoch, get_accuracy(model, test_X, test_y)))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 1.115405\n",
      "Accuracy after iteration 0: 0.366667\n",
      "Loss after iteration 1: 1.091967\n",
      "Accuracy after iteration 1: 0.200000\n",
      "Loss after iteration 2: 1.086035\n",
      "Accuracy after iteration 2: 0.200000\n",
      "Loss after iteration 3: 1.082791\n",
      "Accuracy after iteration 3: 0.200000\n",
      "Loss after iteration 4: 1.079677\n",
      "Accuracy after iteration 4: 0.200000\n",
      "Loss after iteration 5: 1.076136\n",
      "Accuracy after iteration 5: 0.200000\n",
      "Loss after iteration 6: 1.071910\n",
      "Accuracy after iteration 6: 0.200000\n",
      "Loss after iteration 7: 1.066722\n",
      "Accuracy after iteration 7: 0.200000\n",
      "Loss after iteration 8: 1.060184\n",
      "Accuracy after iteration 8: 0.233333\n",
      "Loss after iteration 9: 1.051730\n",
      "Accuracy after iteration 9: 0.366667\n",
      "Loss after iteration 10: 1.040525\n",
      "Accuracy after iteration 10: 0.466667\n",
      "Loss after iteration 11: 1.025364\n",
      "Accuracy after iteration 11: 0.633333\n",
      "Loss after iteration 12: 1.004761\n",
      "Accuracy after iteration 12: 0.633333\n",
      "Loss after iteration 13: 0.977938\n",
      "Accuracy after iteration 13: 0.633333\n",
      "Loss after iteration 14: 0.947567\n",
      "Accuracy after iteration 14: 0.633333\n",
      "Loss after iteration 15: 0.919807\n",
      "Accuracy after iteration 15: 0.633333\n",
      "Loss after iteration 16: 0.895967\n",
      "Accuracy after iteration 16: 0.633333\n",
      "Loss after iteration 17: 0.873737\n",
      "Accuracy after iteration 17: 0.633333\n",
      "Loss after iteration 18: 0.852182\n",
      "Accuracy after iteration 18: 0.700000\n",
      "Loss after iteration 19: 0.831048\n",
      "Accuracy after iteration 19: 0.800000\n",
      "Loss after iteration 20: 0.810341\n",
      "Accuracy after iteration 20: 0.800000\n",
      "Loss after iteration 21: 0.790144\n",
      "Accuracy after iteration 21: 0.800000\n",
      "Loss after iteration 22: 0.770557\n",
      "Accuracy after iteration 22: 0.800000\n",
      "Loss after iteration 23: 0.751669\n",
      "Accuracy after iteration 23: 0.833333\n",
      "Loss after iteration 24: 0.733547\n",
      "Accuracy after iteration 24: 0.866667\n",
      "Loss after iteration 25: 0.716233\n",
      "Accuracy after iteration 25: 0.866667\n",
      "Loss after iteration 26: 0.699748\n",
      "Accuracy after iteration 26: 0.866667\n",
      "Loss after iteration 27: 0.684090\n",
      "Accuracy after iteration 27: 0.900000\n",
      "Loss after iteration 28: 0.669240\n",
      "Accuracy after iteration 28: 0.900000\n",
      "Loss after iteration 29: 0.655170\n",
      "Accuracy after iteration 29: 0.900000\n",
      "Loss after iteration 30: 0.641838\n",
      "Accuracy after iteration 30: 0.900000\n",
      "Loss after iteration 31: 0.629200\n",
      "Accuracy after iteration 31: 0.900000\n",
      "Loss after iteration 32: 0.617204\n",
      "Accuracy after iteration 32: 0.900000\n",
      "Loss after iteration 33: 0.605800\n",
      "Accuracy after iteration 33: 0.900000\n",
      "Loss after iteration 34: 0.594936\n",
      "Accuracy after iteration 34: 0.933333\n",
      "Loss after iteration 35: 0.584562\n",
      "Accuracy after iteration 35: 0.933333\n",
      "Loss after iteration 36: 0.574627\n",
      "Accuracy after iteration 36: 0.933333\n",
      "Loss after iteration 37: 0.565082\n",
      "Accuracy after iteration 37: 0.933333\n",
      "Loss after iteration 38: 0.555880\n",
      "Accuracy after iteration 38: 0.933333\n",
      "Loss after iteration 39: 0.546973\n",
      "Accuracy after iteration 39: 0.933333\n",
      "Loss after iteration 40: 0.538313\n",
      "Accuracy after iteration 40: 0.933333\n",
      "Loss after iteration 41: 0.529849\n",
      "Accuracy after iteration 41: 0.933333\n",
      "Loss after iteration 42: 0.521528\n",
      "Accuracy after iteration 42: 0.933333\n",
      "Loss after iteration 43: 0.513289\n",
      "Accuracy after iteration 43: 0.933333\n",
      "Loss after iteration 44: 0.505066\n",
      "Accuracy after iteration 44: 0.933333\n",
      "Loss after iteration 45: 0.496778\n",
      "Accuracy after iteration 45: 0.933333\n",
      "Loss after iteration 46: 0.488338\n",
      "Accuracy after iteration 46: 0.933333\n",
      "Loss after iteration 47: 0.479656\n",
      "Accuracy after iteration 47: 0.933333\n",
      "Loss after iteration 48: 0.470680\n",
      "Accuracy after iteration 48: 0.933333\n",
      "Loss after iteration 49: 0.461472\n",
      "Accuracy after iteration 49: 0.966667\n"
     ]
    }
   ],
   "source": [
    "model = trainer(16, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:factnlp]",
   "language": "python",
   "name": "conda-env-factnlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
